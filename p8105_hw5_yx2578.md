Homework 5
================
Vera Xu

This is my solution to HW5.

``` r
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
  )

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
  )

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 demo by Jeff in class

Read in the data.

``` r
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Let’s look at this a bit

``` r
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

``` r
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)
  ) %>% 
  broom::tidy()
```

    ## # A tibble: 1 x 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

Try to iterate ……..

``` r
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

``` r
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw5_yx2578_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

## Problem 2

##### Create a dataframe containing all file names for p2

``` r
p2_list = 
  list.files("./data/p2_data")
```

##### Iterate over file names and read in data for each subject

``` r
p2_load = function(file_list) 
  {
  path = str_c("./data/p2_data/", file_list)
  read_csv(path)
  }

p2_data = 
  purrr::map(p2_list, p2_load) %>%
  bind_rows() %>%
  mutate(file_name = p2_list)
```

##### Tidy the result

``` r
p2_tidy_data = 
  p2_data %>%
  mutate(file_name = gsub(".csv", "", file_name)) %>%
  separate(file_name, into = c("trt_group", "id"), sep = "_") %>%
  pivot_longer(week_1:week_8, 
               names_to = "week",
               values_to = "value") %>%
  mutate(week = gsub("week_", "", week))

p2_tidy_data
```

    ## # A tibble: 160 x 4
    ##    trt_group id    week  value
    ##    <chr>     <chr> <chr> <dbl>
    ##  1 con       01    1      0.2 
    ##  2 con       01    2     -1.31
    ##  3 con       01    3      0.66
    ##  4 con       01    4      1.96
    ##  5 con       01    5      0.23
    ##  6 con       01    6      1.09
    ##  7 con       01    7      0.05
    ##  8 con       01    8      1.94
    ##  9 con       02    1      1.13
    ## 10 con       02    2     -0.88
    ## # … with 150 more rows

##### Make a spaghetti plot showing observations on each subject over time

``` r
p2_tidy_data %>%
  ggplot(aes(x=week, y=value, color=id, group = id)) + 
  geom_point() + 
  geom_line() +
  facet_grid(. ~ trt_group)
```

<img src="p8105_hw5_yx2578_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

We can tell from the spaghetti plot above that the values of measurement
in the control group is in general lower than the experiment group. The
values of control group remained flat over the 8 weeks of follow-up,
while the values of experiment group steadily increased over the 8 weeks
of follow-up.

## Problem 3

##### Define function *one\_sample\_ttest* to generate sample dataset and perform one ttest

``` r
n = 30
sigma = 5

one_sample_ttest = function(mu, h_null) {
  
  sample_data = tibble(
    x = rnorm(n=30, mean = mu, sd = 5),
  )
  
  sample_data %>% 
    t.test(mu = h_null) %>%
    broom::tidy()
}
```

##### Define function *one\_sample\_ttest* to generate a df for repeated 5000 tests for any given normal mu = k

``` r
repeat_5000_ttest = function(k) {
  
output_ttest = vector("list", 5000)

for (i in 1:5000) {
  output_ttest[[i]] = one_sample_ttest(mu = k, h_null = 0)
}

ttest_results = bind_rows(output_ttest)
}
```

##### Set mu=0 and perform the result

``` r
result_0 = 
  repeat_5000_ttest(k=0) %>%
  mutate (mu = 0) %>%
  select(mu, estimate:alternative) %>%
  mutate(decision = case_when(p.value < 0.05 ~ "rej", p.value >=0.05 ~ "fail to rej"))

result_0
```

    ## # A tibble: 5,000 x 10
    ##       mu estimate statistic p.value parameter conf.low conf.high method
    ##    <dbl>    <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr> 
    ##  1     0   -0.402    -0.466   0.645        29   -2.16      1.36  One S…
    ##  2     0    1.06      1.17    0.253        29   -0.799     2.92  One S…
    ##  3     0    0.463     0.457   0.651        29   -1.61      2.54  One S…
    ##  4     0    1.02      1.34    0.191        29   -0.537     2.57  One S…
    ##  5     0   -0.522    -0.614   0.544        29   -2.26      1.22  One S…
    ##  6     0   -1.11     -1.24    0.227        29   -2.95      0.729 One S…
    ##  7     0    0.784     0.715   0.480        29   -1.46      3.03  One S…
    ##  8     0    0.136     0.191   0.850        29   -1.32      1.59  One S…
    ##  9     0   -0.433    -0.553   0.584        29   -2.03      1.17  One S…
    ## 10     0    0.346     0.296   0.770        29   -2.05      2.74  One S…
    ## # … with 4,990 more rows, and 2 more variables: alternative <chr>,
    ## #   decision <chr>

##### Repeat the test above for mu={1,2,3,4,5,6} and generate a result summary dataframe with decision with regards to the null hypothesis

``` r
result_0to6 = 
  tibble(mu = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    results = map(.x = mu, ~repeat_5000_ttest(k=.x))
    )

result_summ = 
  result_0to6 %>% 
  unnest(c(mu, results)) %>%
  mutate(decision = case_when(p.value < 0.05 ~ "rej", p.value >=0.05 ~ "fail to rej"))

result_summ
```

    ## # A tibble: 35,000 x 10
    ##       mu estimate statistic p.value parameter conf.low conf.high method
    ##    <dbl>    <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr> 
    ##  1     0  -1.26     -1.32     0.196        29   -3.21      0.689 One S…
    ##  2     0   1.25      1.37     0.180        29   -0.609     3.10  One S…
    ##  3     0  -0.740    -0.926    0.362        29   -2.37      0.894 One S…
    ##  4     0  -0.564    -0.636    0.530        29   -2.38      1.25  One S…
    ##  5     0  -0.311    -0.361    0.720        29   -2.07      1.45  One S…
    ##  6     0   0.216     0.179    0.859        29   -2.26      2.69  One S…
    ##  7     0   0.771     1.05     0.303        29   -0.733     2.27  One S…
    ##  8     0  -1.19     -1.22     0.233        29   -3.19      0.808 One S…
    ##  9     0  -0.0386   -0.0393   0.969        29   -2.04      1.97  One S…
    ## 10     0   0.829     0.695    0.493        29   -1.61      3.27  One S…
    ## # … with 34,990 more rows, and 2 more variables: alternative <chr>,
    ## #   decision <chr>

##### Make a plot showing the proportion of times the null was rejected and value of mu

``` r
result_summ %>%
  group_by(mu) %>%
  summarize(
    n = n(),
    rej_rate = sum(p.value < 0.05)/n) %>% 
  ggplot(aes(x = mu, y = rej_rate)) +
  geom_point() +
    labs(x = "true mean",
         y = "rejection rate") + 
  xlim(0, 6) + 
  ylim(0, 1)
```

<img src="p8105_hw5_yx2578_files/figure-gfm/unnamed-chunk-15-1.png" width="90%" />

Based on the plot above, as effect size (the difference between true
mean and null value) increases, the confidence to reject the null
hypothesis also increases, and the proportion of times the null was
rejected also increases, which means the power of the test increases.

##### Plot describing sample mean and true mean

``` r
library("patchwork")

p1 <-  
  result_summ %>%
  group_by(mu) %>%
  summarize(
    avg_mu_hat = mean(estimate)) %>% 
  ggplot(aes(x = mu, avg_mu_hat)) +
  geom_point() +
    labs(x = "true mean",
         y = "average of estimate",
         title = "All samples") 


p2 <-  
  result_summ %>%
  group_by(mu) %>%
  filter(decision == "rej") %>%
  summarize(
    avg_mu_hat = mean(estimate)) %>% 
  ggplot(aes(x = mu, avg_mu_hat)) +
  geom_point() +
  labs(x = "true mean",
       y = "average of estimate",
       title = "Samples with rejection of null hypothesis")

p1 + p2
```

<img src="p8105_hw5_yx2578_files/figure-gfm/unnamed-chunk-16-1.png" width="90%" />

  - In the left plot, where all samples were included in the plot, we
    can tell that the average estimate is the same as the true mean.
    This holds true according to the CTL.

  - In the right plot, we see that the average estimate of true mean = 0
    is 0 within the rejected null subset, this is because the values we
    reject are randomly distributed above or below 0. However, the
    average of estimate is quite different from the true mean when it’s
    greater than 0. Especially when the power is relatively low, the
    average estimate of the reject subset is higher. As power increases,
    the average of estimate gets closer to the true mean among the
    samples where the null hypothesis is rejected.

  - This indicates that when the effect size is relatively small, there
    are random chances that we will get a overestimate of the mean.
